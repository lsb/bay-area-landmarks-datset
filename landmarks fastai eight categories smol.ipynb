{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8a0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffda1473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_landmark(path):\n",
    "    return path.split(\".\")[0]\n",
    "\n",
    "all_image_files = get_image_files(\"./eight-categories/\")\n",
    "len(all_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29519da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func(\n",
    "    \".\", all_image_files, valid_pct=0.2, seed=42, label_func=get_landmark, item_tfms=Resize(128), bs=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54dd7aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bay-bridge',\n",
       " 'castro',\n",
       " 'coit-tower',\n",
       " 'golden-gate-bridge',\n",
       " 'port-of-oakland',\n",
       " 'scribd-logo',\n",
       " 'sutro-tower',\n",
       " 'transamerica-pyramid']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"eight-categories-vocab.json\", \"w\") as f: f.write(json.dumps(list(dls.vocab)))\n",
    "list(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceca6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.491224</td>\n",
       "      <td>0.552495</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.780451</td>\n",
       "      <td>0.324988</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.578308</td>\n",
       "      <td>0.108331</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.438300</td>\n",
       "      <td>0.071081</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.325302</td>\n",
       "      <td>0.039056</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.265270</td>\n",
       "      <td>0.034332</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.models import efficientnet_v2_l, efficientnet_v2_m, efficientnet_v2_s, mobilenet_v3_large\n",
    "learn_sq = vision_learner(dls, squeezenet1_1, metrics=[accuracy, top_k_accuracy])\n",
    "learn_sq.fine_tune(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a383496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/eight-categories-sq-128.pth')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_sq.save(\"eight-categories-sq-128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e70ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = learn_sq.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01409711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms\n",
    "softmax_layer = torch.nn.Softmax(dim=1)\n",
    "normalization_layer = torchvision.transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "final_model = nn.Sequential(normalization_layer, pytorch_model, softmax_layer)\n",
    "torch.onnx.export(\n",
    "    final_model, \n",
    "    torch.randn(1, 3, 128, 128).cuda(),\n",
    "    'landmarks-eight-categories.onnx',\n",
    "    do_constant_folding=True,\n",
    "    export_params=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    opset_version=13,\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                 'output' : {0 : 'batch_size'}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b792d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
